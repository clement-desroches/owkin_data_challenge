{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "393c6b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data dimensions: (344, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Center ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_001.npy</td>\n",
       "      <td>P_001</td>\n",
       "      <td>C_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_002.npy</td>\n",
       "      <td>P_002</td>\n",
       "      <td>C_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_005.npy</td>\n",
       "      <td>P_005</td>\n",
       "      <td>C_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_006.npy</td>\n",
       "      <td>P_006</td>\n",
       "      <td>C_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_007.npy</td>\n",
       "      <td>P_007</td>\n",
       "      <td>C_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample ID Patient ID Center ID  Target\n",
       "0  ID_001.npy      P_001       C_1       0\n",
       "1  ID_002.npy      P_002       C_2       1\n",
       "2  ID_005.npy      P_005       C_5       0\n",
       "3  ID_006.npy      P_006       C_5       0\n",
       "4  ID_007.npy      P_007       C_2       1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "# put your own path to the data root directory (see example in `Data architecture` section)\n",
    "data_dir = Path(\"..\")\n",
    "\n",
    "# load the training and testing data sets\n",
    "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
    "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
    "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
    "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
    "\n",
    "# concatenate y_train and df_train\n",
    "y_train = pd.read_csv(data_dir  / \"train_output_76GDcgx.csv\")\n",
    "df_train = df_train.merge(y_train, on=\"Sample ID\")\n",
    "\n",
    "print(f\"Training data dimensions: {df_train.shape}\")  # (344, 4)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c6a87f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 344/344 [00:01<00:00, 179.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "centers_train = []\n",
    "patients_train = []\n",
    "\n",
    "for sample, label, center, patient in tqdm(\n",
    "    df_train[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
    "):\n",
    "    # load the coordinates and features (1000, 3+2048)\n",
    "    _features = np.load(train_features_dir / sample)\n",
    "    # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
    "    # and the MoCo V2 features\n",
    "    coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
    "    # slide-level averaging\n",
    "    #X_train.append(np.mean(features, axis=0))\n",
    "    \n",
    "    X_train.append(features)\n",
    "    y_train.append([label])\n",
    "    centers_train.append(center)\n",
    "    patients_train.append(patient)\n",
    "\n",
    "# convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "centers_train = np.array(centers_train)\n",
    "patients_train = np.array(patients_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cff3d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98166891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_y(y):\n",
    "    y_reduced = list()\n",
    "    for y_ in y:\n",
    "        y_reduced.append(np.array([y_[0]]))\n",
    "    return np.array(y_reduced)\n",
    "\n",
    "\n",
    "def train_val_test_split(X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the input data into training, testing, and validation sets\n",
    "    Args:\n",
    "        X: input data\n",
    "        y: labels\n",
    "        train_size: proportion of data to be used for training\n",
    "        val_size: proportion of data to be used for validation\n",
    "        test_size: proportion of data to be used for testing\n",
    "        random_state: seed for random number generator\n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "    idx = np.random.permutation(n_samples)\n",
    "    X, y = X[idx], y[idx]\n",
    "    train_end = int(train_size * n_samples)\n",
    "    val_end = int((train_size + val_size) * n_samples)\n",
    "    X_train, y_train = X[:train_end], y[:train_end]\n",
    "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "    X_test, y_test = X[val_end:], y[val_end:]\n",
    "    return X_train, X_val, X_test, reduce_y(y_train), reduce_y(y_val), reduce_y(y_test)\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X_train, y_train, train_size=0.8, val_size=.2, test_size=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0751a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "58660fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([275, 1000, 2048])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa75c2",
   "metadata": {},
   "source": [
    "fe_1("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecddad",
   "metadata": {},
   "source": [
    "Their tiles : 16x128x128\n",
    "\n",
    "ours : 1000x2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9a86d",
   "metadata": {},
   "source": [
    "##### Them:\n",
    "\n",
    "16x128x128x3 -> FA2 & FA2 -> 512,1 ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee06b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 2048 # 512 node fully connected layer\n",
    "        self.D = 16 # 128 node attention layer\n",
    "        self.K = 1\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L * self.K, 1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        H = x #self.L\n",
    "        A = self.attention(H) # NxK\n",
    "        A = torch.transpose(A, 1, 0) # KxN\n",
    "        A = F.softmax(A, dim=1) # softmax over N\n",
    "        M = torch.mm(A, H)\n",
    "       # The probability that a given bag is malignant or benign\n",
    "        Y_prob = self.classifier(M) \n",
    "        # The prediction given the probability (Y_prob >= 0.5 returns a Y_hat of 1 meaning malignant)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "        return Y_prob, Y_hat, A.byte()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat, _ = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().data\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _, A = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))\n",
    "\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "519f5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model,X_train,y_train, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for bag_idx,x in enumerate(X_train):\n",
    "        bag_label = y_train[bag_idx]\n",
    "        \n",
    "        #for idx,data in enumerate(x): #de 0 à 1000\n",
    "        #data = torch.squeeze(data) #a voir\n",
    "            \n",
    "        data = torch.squeeze(x)    \n",
    "        \n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate loss\n",
    "        loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "        train_loss += loss.data[0]\n",
    "        # Calculate error\n",
    "        error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "        train_error += error\n",
    "\n",
    "        # Keep track of predictions and labels to calculate accuracy after each epoch\n",
    "        _, Y_hat, _ = model(data)\n",
    "        predictions.append(int(Y_hat)) \n",
    "        labels.append(int(bag_label))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "    train_loss /= len(X_train)\n",
    "    train_error /= len(X_train)\n",
    "    print('Train Set, Epoch: {}, Loss: {:.4f}, Error: {:.4f}, Accuracy: {:.2f}%'.format(epoch, train_loss.cpu().numpy()[0], train_error, accuracy_score(labels, predictions)*100))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4b77c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,X_val,y_val):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_error = 0.\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for bag_idx,x in enumerate(X_val):\n",
    "            bag_label = y_train[bag_idx]\n",
    "            data = torch.squeeze(x) \n",
    "            data, bag_label = Variable(data), Variable(bag_label)\n",
    "\n",
    "\n",
    "            loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "            test_loss += loss.data[0]\n",
    "            error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "            test_error += error\n",
    "        \n",
    "        test_error /= len(X_val)\n",
    "        test_loss /= len(X_val)\n",
    "        \n",
    "        print('Val Set, Loss: {:.4f}, Error: {:.4f}'.format(test_loss.cpu().numpy()[0], test_error))\n",
    "        print('=====================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "99afe53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([275, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "17cbaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Train Set, Epoch: 1, Loss: 0.6771, Error: 0.3709, Accuracy: 62.55%\n",
      "Val Set, Loss: 0.6570, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 2, Loss: 0.6661, Error: 0.4109, Accuracy: 59.64%\n",
      "Val Set, Loss: 0.6459, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 3, Loss: 0.6568, Error: 0.4109, Accuracy: 57.09%\n",
      "Val Set, Loss: 0.6383, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 4, Loss: 0.6549, Error: 0.4145, Accuracy: 62.18%\n",
      "Val Set, Loss: 0.6345, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 5, Loss: 0.6444, Error: 0.3782, Accuracy: 56.36%\n",
      "Val Set, Loss: 0.6300, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 6, Loss: 0.6411, Error: 0.4109, Accuracy: 62.18%\n",
      "Val Set, Loss: 0.6278, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 7, Loss: 0.6368, Error: 0.3527, Accuracy: 61.09%\n",
      "Val Set, Loss: 0.6271, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 8, Loss: 0.6481, Error: 0.4436, Accuracy: 60.36%\n",
      "Val Set, Loss: 0.6277, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 9, Loss: 0.6476, Error: 0.4218, Accuracy: 58.91%\n",
      "Val Set, Loss: 0.6289, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 10, Loss: 0.6274, Error: 0.3527, Accuracy: 61.45%\n",
      "Val Set, Loss: 0.6278, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 11, Loss: 0.6393, Error: 0.4109, Accuracy: 64.36%\n",
      "Val Set, Loss: 0.6285, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 12, Loss: 0.6280, Error: 0.4364, Accuracy: 56.36%\n",
      "Val Set, Loss: 0.6282, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 13, Loss: 0.6251, Error: 0.4291, Accuracy: 60.36%\n",
      "Val Set, Loss: 0.6282, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 14, Loss: 0.6230, Error: 0.4545, Accuracy: 60.00%\n",
      "Val Set, Loss: 0.6274, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 15, Loss: 0.6209, Error: 0.4255, Accuracy: 54.91%\n",
      "Val Set, Loss: 0.6287, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 16, Loss: 0.6217, Error: 0.3964, Accuracy: 58.18%\n",
      "Val Set, Loss: 0.6291, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 17, Loss: 0.6165, Error: 0.3782, Accuracy: 59.27%\n",
      "Val Set, Loss: 0.6289, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 18, Loss: 0.6140, Error: 0.3818, Accuracy: 60.36%\n",
      "Val Set, Loss: 0.6301, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 19, Loss: 0.6085, Error: 0.3782, Accuracy: 61.82%\n",
      "Val Set, Loss: 0.6296, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 20, Loss: 0.6142, Error: 0.4109, Accuracy: 53.09%\n",
      "Val Set, Loss: 0.6317, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 21, Loss: 0.6161, Error: 0.4400, Accuracy: 58.91%\n",
      "Val Set, Loss: 0.6340, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 22, Loss: 0.6013, Error: 0.4109, Accuracy: 57.45%\n",
      "Val Set, Loss: 0.6333, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 23, Loss: 0.6141, Error: 0.4036, Accuracy: 57.09%\n",
      "Val Set, Loss: 0.6353, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 24, Loss: 0.6126, Error: 0.4182, Accuracy: 61.09%\n",
      "Val Set, Loss: 0.6376, Error: 0.3043\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 25, Loss: 0.6080, Error: 0.3818, Accuracy: 61.45%\n",
      "Val Set, Loss: 0.6393, Error: 0.3188\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 26, Loss: 0.5970, Error: 0.3455, Accuracy: 64.00%\n",
      "Val Set, Loss: 0.6377, Error: 0.3188\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 27, Loss: 0.5863, Error: 0.3782, Accuracy: 60.00%\n",
      "Val Set, Loss: 0.6371, Error: 0.3188\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 28, Loss: 0.5851, Error: 0.3855, Accuracy: 59.27%\n",
      "Val Set, Loss: 0.6393, Error: 0.3333\n",
      "=====================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     test(model, X_val, y_val)\n",
      "Cell \u001b[0;32mIn[123], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, optimizer, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Calculate error\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m error, predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_classification_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbag_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m train_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m error\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Keep track of predictions and labels to calculate accuracy after each epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[122], line 44\u001b[0m, in \u001b[0;36mAttention.calculate_classification_error\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     42\u001b[0m Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     43\u001b[0m _, Y_hat, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m---> 44\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mY_hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error, Y_hat\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Attention()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.999), weight_decay=0.0005)\n",
    "\n",
    "print('Start Training')\n",
    "\n",
    "EPOCHS = 30\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, X_train,y_train, optimizer, epoch)\n",
    "    test(model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, args.model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
