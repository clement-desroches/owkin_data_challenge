{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27df6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data dimensions: (344, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Center ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_001.npy</td>\n",
       "      <td>P_001</td>\n",
       "      <td>C_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_002.npy</td>\n",
       "      <td>P_002</td>\n",
       "      <td>C_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_005.npy</td>\n",
       "      <td>P_005</td>\n",
       "      <td>C_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_006.npy</td>\n",
       "      <td>P_006</td>\n",
       "      <td>C_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_007.npy</td>\n",
       "      <td>P_007</td>\n",
       "      <td>C_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample ID Patient ID Center ID  Target\n",
       "0  ID_001.npy      P_001       C_1       0\n",
       "1  ID_002.npy      P_002       C_2       1\n",
       "2  ID_005.npy      P_005       C_5       0\n",
       "3  ID_006.npy      P_006       C_5       0\n",
       "4  ID_007.npy      P_007       C_2       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "# put your own path to the data root directory (see example in `Data architecture` section)\n",
    "data_dir = Path(\"..\")\n",
    "\n",
    "# load the training and testing data sets\n",
    "train_features_dir = data_dir / \"train_input\" / \"moco_features\"\n",
    "test_features_dir = data_dir / \"test_input\" / \"moco_features\"\n",
    "df_train = pd.read_csv(data_dir  / \"supplementary_data\" / \"train_metadata.csv\")\n",
    "df_test = pd.read_csv(data_dir  / \"supplementary_data\" / \"test_metadata.csv\")\n",
    "\n",
    "# concatenate y_train and df_train\n",
    "y_train = pd.read_csv(data_dir  / \"train_output_76GDcgx.csv\")\n",
    "df_train = df_train.merge(y_train, on=\"Sample ID\")\n",
    "\n",
    "print(f\"Training data dimensions: {df_train.shape}\")  # (344, 4)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f33791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 344/344 [00:01<00:00, 280.10it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "centers_train = []\n",
    "patients_train = []\n",
    "\n",
    "for sample, label, center, patient in tqdm(\n",
    "    df_train[[\"Sample ID\", \"Target\", \"Center ID\", \"Patient ID\"]].values\n",
    "):\n",
    "    # load the coordinates and features (1000, 3+2048)\n",
    "    _features = np.load(train_features_dir / sample)\n",
    "    # get coordinates (zoom level, tile x-coord on the slide, tile y-coord on the slide)\n",
    "    # and the MoCo V2 features\n",
    "    coordinates, features = _features[:, :3], _features[:, 3:]  # Ks\n",
    "    # slide-level averaging\n",
    "    #X_train.append(np.mean(features, axis=0))\n",
    "    \n",
    "    X_train.append(features)\n",
    "    y_train.append([label])\n",
    "    centers_train.append(center)\n",
    "    patients_train.append(patient)\n",
    "\n",
    "# convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "centers_train = np.array(centers_train)\n",
    "patients_train = np.array(patients_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d177fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdb8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_y(y):\n",
    "    y_reduced = list()\n",
    "    for y_ in y:\n",
    "        y_reduced.append(np.array([y_[0]]))\n",
    "    return np.array(y_reduced)\n",
    "\n",
    "\n",
    "def train_val_test_split(X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the input data into training, testing, and validation sets\n",
    "    Args:\n",
    "        X: input data\n",
    "        y: labels\n",
    "        train_size: proportion of data to be used for training\n",
    "        val_size: proportion of data to be used for validation\n",
    "        test_size: proportion of data to be used for testing\n",
    "        random_state: seed for random number generator\n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "    idx = np.random.permutation(n_samples)\n",
    "    X, y = X[idx], y[idx]\n",
    "    train_end = int(train_size * n_samples)\n",
    "    val_end = int((train_size + val_size) * n_samples)\n",
    "    X_train, y_train = X[:train_end], y[:train_end]\n",
    "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "    X_test, y_test = X[val_end:], y[val_end:]\n",
    "    return X_train, X_val, X_test, reduce_y(y_train), reduce_y(y_val), reduce_y(y_test)\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X_train, y_train, train_size=0.8, val_size=.2, test_size=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9b182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3515a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([275, 1000, 2048])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3df0a9",
   "metadata": {},
   "source": [
    "fe_1("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7af55c",
   "metadata": {},
   "source": [
    "Their tiles : 16x128x128\n",
    "\n",
    "ours : 1000x2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e389097",
   "metadata": {},
   "source": [
    "##### Them:\n",
    "\n",
    "16x128x128x3 -> FA2 & FA2 -> 512,1 ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ec2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.L = 2048 # 512 node fully connected layer\n",
    "        self.D = 16 # 128 node attention layer\n",
    "        self.K = 1\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.L, self.D),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.D, self.K),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.L * self.K, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        H = x #self.L\n",
    "        A = self.attention(H) # NxK\n",
    "        A = torch.transpose(A, 1, 0) # KxN\n",
    "        A = F.softmax(A, dim=1) # softmax over N\n",
    "        M = torch.mm(A, H)\n",
    "       # The probability that a given bag is malignant or benign\n",
    "        Y_prob = self.classifier(M) \n",
    "        # The prediction given the probability (Y_prob >= 0.5 returns a Y_hat of 1 meaning malignant)\n",
    "        Y_hat = torch.ge(Y_prob, 0.5).float()\n",
    "        return Y_prob, Y_hat, A.byte()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_classification_error(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        _, Y_hat, _ = self.forward(X)\n",
    "        error = 1. - Y_hat.eq(Y).cpu().float().mean().data\n",
    "\n",
    "        return error, Y_hat\n",
    "\n",
    "    def calculate_objective(self, X, Y):\n",
    "        Y = Y.float()\n",
    "        Y_prob, _, A = self.forward(X)\n",
    "        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)\n",
    "        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))\n",
    "\n",
    "        return neg_log_likelihood, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fd481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model,X_train,y_train, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_error = 0.\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for bag_idx,x in enumerate(X_train):\n",
    "        bag_label = y_train[bag_idx]\n",
    "        \n",
    "        #for idx,data in enumerate(x): #de 0 à 1000\n",
    "        #data = torch.squeeze(data) #a voir\n",
    "            \n",
    "        data = torch.squeeze(x)    \n",
    "        \n",
    "        data, bag_label = Variable(data), Variable(bag_label)\n",
    "\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate loss\n",
    "        loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "        train_loss += loss.data[0]\n",
    "        # Calculate error\n",
    "        error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "        train_error += error\n",
    "\n",
    "        # Keep track of predictions and labels to calculate accuracy after each epoch\n",
    "        _, Y_hat, _ = model(data)\n",
    "        predictions.append(int(Y_hat)) \n",
    "        labels.append(int(bag_label))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "    train_loss /= len(X_train)\n",
    "    train_error /= len(X_train)\n",
    "    \n",
    "    #metric = accuracy_score(labels, predictions)*100\n",
    "    metric = roc_auc_score(labels, predictions)*100\n",
    "    \n",
    "    print('Train Set, Epoch: {}, Loss: {:.4f}, Error: {:.4f}, ROC AUC: {:.2f}%'.format(epoch, train_loss.cpu().numpy()[0], train_error,metric))\n",
    "\n",
    "    return train_loss,metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a50d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,X_val,y_val):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_error = 0.\n",
    "    \n",
    "    labels = list()\n",
    "    predictions=list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for bag_idx,x in enumerate(X_val):\n",
    "            bag_label = y_train[bag_idx]\n",
    "            data = torch.squeeze(x) \n",
    "            data, bag_label = Variable(data), Variable(bag_label)\n",
    "\n",
    "\n",
    "            loss, attention_weights = model.calculate_objective(data, bag_label)\n",
    "            test_loss += loss.data[0]\n",
    "            error, predicted_label = model.calculate_classification_error(data, bag_label)\n",
    "            \n",
    "            # Keep track of predictions and labels to calculate accuracy after each epoch\n",
    "            _, Y_hat, _ = model(data)\n",
    "            predictions.append(int(Y_hat)) \n",
    "            labels.append(int(bag_label))\n",
    "            test_error += error\n",
    "        \n",
    "        test_error /= len(X_val)\n",
    "        test_loss /= len(X_val)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        metric = roc_auc_score(labels,predictions)*100\n",
    "        print('Val Set, Loss: {:.4f}, Error: {:.4f}, ROC AUC: {:.2f}'.format(test_loss.cpu().numpy()[0], test_error, metric))\n",
    "        print('=====================================================================================')\n",
    "    return test_loss,metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da520dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([275, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa100df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Train Set, Epoch: 1, Loss: 0.6813, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6757, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 2, Loss: 0.6749, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6687, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 3, Loss: 0.6695, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6626, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 4, Loss: 0.6649, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6574, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 5, Loss: 0.6609, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6529, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 6, Loss: 0.6575, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6491, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 7, Loss: 0.6546, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6457, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 8, Loss: 0.6520, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6428, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 9, Loss: 0.6498, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6403, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 10, Loss: 0.6478, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6381, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 11, Loss: 0.6462, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6362, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 12, Loss: 0.6446, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6345, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 13, Loss: 0.6433, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6330, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 14, Loss: 0.6421, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6317, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 15, Loss: 0.6410, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6306, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 16, Loss: 0.6400, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6296, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 17, Loss: 0.6391, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6287, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 18, Loss: 0.6382, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6279, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 19, Loss: 0.6374, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6273, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 20, Loss: 0.6366, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6266, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 21, Loss: 0.6359, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6261, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 22, Loss: 0.6352, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6256, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 23, Loss: 0.6345, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6252, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 24, Loss: 0.6339, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6248, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 25, Loss: 0.6333, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6244, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 26, Loss: 0.6327, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6241, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 27, Loss: 0.6320, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6239, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 28, Loss: 0.6315, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6236, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 29, Loss: 0.6309, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6234, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 30, Loss: 0.6303, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6232, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 31, Loss: 0.6298, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6230, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 32, Loss: 0.6292, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6228, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 33, Loss: 0.6286, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6227, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 34, Loss: 0.6281, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6226, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 35, Loss: 0.6275, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6225, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 36, Loss: 0.6270, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6224, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 37, Loss: 0.6264, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6223, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 38, Loss: 0.6258, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6222, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 39, Loss: 0.6253, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6221, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 40, Loss: 0.6248, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6221, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set, Epoch: 41, Loss: 0.6243, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 42, Loss: 0.6238, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 43, Loss: 0.6230, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 44, Loss: 0.6225, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 45, Loss: 0.6220, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 46, Loss: 0.6215, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 47, Loss: 0.6208, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 48, Loss: 0.6205, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 49, Loss: 0.6199, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 50, Loss: 0.6192, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 51, Loss: 0.6185, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 52, Loss: 0.6181, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6219, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 53, Loss: 0.6175, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 54, Loss: 0.6170, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 55, Loss: 0.6166, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6220, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 56, Loss: 0.6159, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6221, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 57, Loss: 0.6154, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6221, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 58, Loss: 0.6148, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6222, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 59, Loss: 0.6143, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6222, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 60, Loss: 0.6136, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6223, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 61, Loss: 0.6132, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6223, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 62, Loss: 0.6124, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6224, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 63, Loss: 0.6121, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6224, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n",
      "Train Set, Epoch: 64, Loss: 0.6115, Error: 0.3418, ROC AUC: 50.00%\n",
      "Val Set, Loss: 0.6225, Error: 0.3043, ROC AUC: 50.00\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = Attention()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.001)\n",
    "\n",
    "print('Start Training')\n",
    "\n",
    "history_train, history_val = list(),list()\n",
    "\n",
    "EPOCHS = 100\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    history_train += train(model, X_train,y_train, optimizer, epoch)\n",
    "    history_val   += test(model, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c820f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17e954100>,\n",
       " <matplotlib.lines.Line2D at 0x28118cb20>,\n",
       " <matplotlib.lines.Line2D at 0x28118cb50>,\n",
       " <matplotlib.lines.Line2D at 0x28118cc40>,\n",
       " <matplotlib.lines.Line2D at 0x28118cd30>,\n",
       " <matplotlib.lines.Line2D at 0x28118ce20>,\n",
       " <matplotlib.lines.Line2D at 0x28118cf10>,\n",
       " <matplotlib.lines.Line2D at 0x28118cfd0>,\n",
       " <matplotlib.lines.Line2D at 0x281190130>,\n",
       " <matplotlib.lines.Line2D at 0x281190220>,\n",
       " <matplotlib.lines.Line2D at 0x28118cac0>,\n",
       " <matplotlib.lines.Line2D at 0x281190310>,\n",
       " <matplotlib.lines.Line2D at 0x281190400>,\n",
       " <matplotlib.lines.Line2D at 0x2811905b0>,\n",
       " <matplotlib.lines.Line2D at 0x2811906a0>,\n",
       " <matplotlib.lines.Line2D at 0x281190790>,\n",
       " <matplotlib.lines.Line2D at 0x281190880>,\n",
       " <matplotlib.lines.Line2D at 0x281190970>,\n",
       " <matplotlib.lines.Line2D at 0x281190a60>,\n",
       " <matplotlib.lines.Line2D at 0x281190b50>,\n",
       " <matplotlib.lines.Line2D at 0x281190c40>,\n",
       " <matplotlib.lines.Line2D at 0x281190d30>,\n",
       " <matplotlib.lines.Line2D at 0x281190e20>,\n",
       " <matplotlib.lines.Line2D at 0x281190f10>,\n",
       " <matplotlib.lines.Line2D at 0x281190fd0>,\n",
       " <matplotlib.lines.Line2D at 0x281193130>,\n",
       " <matplotlib.lines.Line2D at 0x281193220>,\n",
       " <matplotlib.lines.Line2D at 0x281193310>,\n",
       " <matplotlib.lines.Line2D at 0x281193400>,\n",
       " <matplotlib.lines.Line2D at 0x2811934f0>,\n",
       " <matplotlib.lines.Line2D at 0x2811935e0>,\n",
       " <matplotlib.lines.Line2D at 0x2811936d0>,\n",
       " <matplotlib.lines.Line2D at 0x2811937c0>,\n",
       " <matplotlib.lines.Line2D at 0x2811938b0>,\n",
       " <matplotlib.lines.Line2D at 0x2811939a0>,\n",
       " <matplotlib.lines.Line2D at 0x281193a90>,\n",
       " <matplotlib.lines.Line2D at 0x281193b80>,\n",
       " <matplotlib.lines.Line2D at 0x281193c70>,\n",
       " <matplotlib.lines.Line2D at 0x281193d60>,\n",
       " <matplotlib.lines.Line2D at 0x281193e50>,\n",
       " <matplotlib.lines.Line2D at 0x281193f40>,\n",
       " <matplotlib.lines.Line2D at 0x281196070>,\n",
       " <matplotlib.lines.Line2D at 0x281196160>,\n",
       " <matplotlib.lines.Line2D at 0x281196250>,\n",
       " <matplotlib.lines.Line2D at 0x281196340>,\n",
       " <matplotlib.lines.Line2D at 0x281196430>,\n",
       " <matplotlib.lines.Line2D at 0x281196520>,\n",
       " <matplotlib.lines.Line2D at 0x281196610>,\n",
       " <matplotlib.lines.Line2D at 0x281196700>,\n",
       " <matplotlib.lines.Line2D at 0x2811967f0>,\n",
       " <matplotlib.lines.Line2D at 0x2811968e0>,\n",
       " <matplotlib.lines.Line2D at 0x2811969d0>,\n",
       " <matplotlib.lines.Line2D at 0x281196ac0>,\n",
       " <matplotlib.lines.Line2D at 0x281196bb0>,\n",
       " <matplotlib.lines.Line2D at 0x281196ca0>,\n",
       " <matplotlib.lines.Line2D at 0x281196d90>,\n",
       " <matplotlib.lines.Line2D at 0x281196e80>,\n",
       " <matplotlib.lines.Line2D at 0x281196f70>,\n",
       " <matplotlib.lines.Line2D at 0x2811990a0>,\n",
       " <matplotlib.lines.Line2D at 0x281199190>,\n",
       " <matplotlib.lines.Line2D at 0x281199280>,\n",
       " <matplotlib.lines.Line2D at 0x281199370>,\n",
       " <matplotlib.lines.Line2D at 0x281199460>,\n",
       " <matplotlib.lines.Line2D at 0x281199550>,\n",
       " <matplotlib.lines.Line2D at 0x281199640>,\n",
       " <matplotlib.lines.Line2D at 0x281199730>,\n",
       " <matplotlib.lines.Line2D at 0x281199820>,\n",
       " <matplotlib.lines.Line2D at 0x281199910>,\n",
       " <matplotlib.lines.Line2D at 0x281199a00>,\n",
       " <matplotlib.lines.Line2D at 0x281199af0>,\n",
       " <matplotlib.lines.Line2D at 0x281199be0>,\n",
       " <matplotlib.lines.Line2D at 0x281199cd0>,\n",
       " <matplotlib.lines.Line2D at 0x281199dc0>,\n",
       " <matplotlib.lines.Line2D at 0x281199eb0>,\n",
       " <matplotlib.lines.Line2D at 0x281199fa0>,\n",
       " <matplotlib.lines.Line2D at 0x28119f0d0>,\n",
       " <matplotlib.lines.Line2D at 0x28119f1c0>,\n",
       " <matplotlib.lines.Line2D at 0x28119f2b0>,\n",
       " <matplotlib.lines.Line2D at 0x28119f3a0>,\n",
       " <matplotlib.lines.Line2D at 0x28119f490>,\n",
       " <matplotlib.lines.Line2D at 0x28119f580>,\n",
       " <matplotlib.lines.Line2D at 0x28119f670>,\n",
       " <matplotlib.lines.Line2D at 0x28119f760>,\n",
       " <matplotlib.lines.Line2D at 0x28119f850>,\n",
       " <matplotlib.lines.Line2D at 0x28119f940>,\n",
       " <matplotlib.lines.Line2D at 0x28119fa30>,\n",
       " <matplotlib.lines.Line2D at 0x28119fb20>,\n",
       " <matplotlib.lines.Line2D at 0x28119fc10>,\n",
       " <matplotlib.lines.Line2D at 0x28119fd00>,\n",
       " <matplotlib.lines.Line2D at 0x28119fdf0>,\n",
       " <matplotlib.lines.Line2D at 0x28119fee0>,\n",
       " <matplotlib.lines.Line2D at 0x28119ffd0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a3100>,\n",
       " <matplotlib.lines.Line2D at 0x2811a31f0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a32e0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a33d0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a35b0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a34c0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a36a0>,\n",
       " <matplotlib.lines.Line2D at 0x2811a36d0>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, args.model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
